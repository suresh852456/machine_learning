{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import sklearn.metrics as metrics\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools import add_constant as add_constant\n",
    "#from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input data\n"
     ]
    }
   ],
   "source": [
    "## Reading Data\n",
    "print(\"Reading input data\")\n",
    "trainingDataset=pd.read_excel('Encoded_data_binary.xlsx')\n",
    "Error_data = pd.read_excel(\"data/Error_Encoding.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "Error_data['Error_split'] = Error_data['Error'].apply(lambda x:x.split(\".\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_stats(target_actual_res , positive_class_prob_score,target_model_res = None):\n",
    "    \n",
    "    false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(target_actual_res, positive_class_prob_score)\n",
    "    auc_val = metrics.auc(false_positive_rate, true_positive_rate)\n",
    "    if target_model_res is None:\n",
    "        confusion_mat = \"Not Available\"\n",
    "    else:\n",
    "        confusion_mat = pd.crosstab(np.asarray(target_actual_res), np.asarray(target_model_res), rownames=['Actual'], colnames=['Predicted'])\n",
    "        print(confusion_mat)\n",
    "        print(\"\\nPrecision is: \", metrics.precision_score(target_actual_res, target_model_res))\n",
    "        print(\"Recall is: \", metrics.recall_score(target_actual_res, target_model_res))\n",
    "        print(\"Overall_Accuracy is: \", metrics.accuracy_score(target_actual_res,target_model_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "Error_data  = Error_data.groupby('Encoded value').agg({'Error_split':'first'}).drop_duplicates().reset_index()\n",
    "Error_data.columns = ['Encoded value','Error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDataset = trainingDataset.merge(Error_data, left_on='PrimaryCause', right_on='Encoded value', how='left').rename(columns={'Error':'PrimaryCause','PrimaryCause':'PrimaryCause_y'})\n",
    "\n",
    "trainingDataset = trainingDataset.merge(Error_data, left_on='Cause1', right_on='Encoded value', how='left').rename(columns={'Error':'Cause1','Cause1':'Cause1_y'})\n",
    "trainingDataset = trainingDataset.merge(Error_data, left_on='Cause2', right_on='Encoded value', how='left').rename(columns={'Error':'Cause2','Cause2':'Cause2_y'})\n",
    "trainingDataset = trainingDataset.merge(Error_data, left_on='Cause3', right_on='Encoded value', how='left').rename(columns={'Error':'Cause3','Cause3':'Cause3_y'})\n",
    "trainingDataset = trainingDataset.merge(Error_data, left_on='Cause4', right_on='Encoded value', how='left').rename(columns={'Error':'Cause4','Cause4':'Cause4_y'})\n",
    "#trainingDataset = trainingDataset.merge(Error_data, left_on='Cause5', right_on='Encoded value', how='left').rename(columns={'Error':'Cause5','Cause5':'Cause5_y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDataset['Cause1'] = trainingDataset['Cause1'].fillna(value=trainingDataset['PrimaryCause'])\n",
    "trainingDataset['Cause2'] = trainingDataset['Cause2'].fillna(value=trainingDataset['PrimaryCause'])\n",
    "trainingDataset['Cause3'] = trainingDataset['Cause3'].fillna(value=trainingDataset['PrimaryCause'])\n",
    "trainingDataset['Cause4'] = trainingDataset['Cause4'].fillna(value=trainingDataset['PrimaryCause'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_summary = trainingDataset['Summary'].tolist()\n",
    "tokens_primary = trainingDataset['PrimaryCause'].tolist()\n",
    "tokens_cause1 = trainingDataset['Cause1'].tolist()\n",
    "tokens_cause2 = trainingDataset['Cause2'].tolist()\n",
    "tokens_cause3 = trainingDataset['Cause3'].tolist()\n",
    "tokens_cause4 = trainingDataset['Cause4'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary = Word2Vec(sentences=tokens_summary, vector_size=10, workers=4, seed=SEED)\n",
    "model_primary = Word2Vec(sentences=tokens_primary, vector_size=5, workers=4, seed=SEED)\n",
    "model_cause1 = Word2Vec(sentences=tokens_cause1, vector_size=5, workers=4, seed=SEED)\n",
    "model_cause2 = Word2Vec(sentences=tokens_cause2, vector_size=5, workers=4, seed=SEED)\n",
    "model_cause3 = Word2Vec(sentences=tokens_cause3, vector_size=5, workers=4, seed=SEED)\n",
    "model_cause4 = Word2Vec(sentences=tokens_cause4, vector_size=5, workers=4, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(list_of_docs, model):\n",
    "    \"\"\"Generate vectors for list of documents using a Word Embedding\n",
    "\n",
    "    Args:\n",
    "        list_of_docs: List of documents\n",
    "        model: Gensim's Word Embedding\n",
    "\n",
    "    Returns:\n",
    "        List of document vectors\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    for tokens in list_of_docs:\n",
    "        zero_vector = np.zeros(model.vector_size)\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            if token in model.wv:\n",
    "                try:\n",
    "                    vectors.append(model.wv[token])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        if vectors:\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis=0)\n",
    "            features.append(avg_vec)\n",
    "        else:\n",
    "            features.append(zero_vector)\n",
    "    return features\n",
    "\n",
    "vectorized_summary = vectorize(tokens_summary, model=model_summary)\n",
    "vectorized_primary = vectorize(tokens_primary, model=model_primary)\n",
    "vectorized_cause1 = vectorize(tokens_cause1, model=model_cause1)\n",
    "vectorized_cause2 = vectorize(tokens_cause2, model=model_cause2)\n",
    "vectorized_cause3 = vectorize(tokens_cause3, model=model_cause3)\n",
    "vectorized_cause4 = vectorize(tokens_cause4, model=model_cause4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_summary = pd.DataFrame(vectorized_summary, columns=['summary.1','summary.2','summary.3','summary.4','summary.5','summary.6','summary.7','summary.8','summary.9','summary.10'])\n",
    "vectorized_primary = pd.DataFrame(vectorized_primary, columns=['primary.1','primary.2','primary.3','primary.4','primary.5'])\n",
    "vectorized_cause1 = pd.DataFrame(vectorized_cause1, columns=['cause1.1','cause1.2','cause1.3','cause1.4','cause1.5'])\n",
    "vectorized_cause2 = pd.DataFrame(vectorized_cause2, columns=['cause2.1','cause2.2','cause2.3','cause2.4','cause2.5'])\n",
    "vectorized_cause3 = pd.DataFrame(vectorized_cause3, columns=['cause3.1','cause3.2','cause3.3','cause3.4','cause3.5'])\n",
    "vectorized_cause4 = pd.DataFrame(vectorized_cause4, columns=['cause4.1','cause4.2','cause4.3','cause4.4','cause4.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDataset = pd.concat([trainingDataset,vectorized_summary,vectorized_primary,vectorized_cause1,vectorized_cause2,vectorized_cause3,vectorized_cause4], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data = trainingDataset.groupby('BinaryLabel').apply(lambda x:x.sample(n=131)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Over Sampling balancing\n",
    "data = trainingDataset.copy()\n",
    "## Under Sampling balancing\n",
    "b_data = balanced_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_consider = data.columns[27:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, cols_consider]\n",
    "#sca = StandardScaler()\n",
    "#X = sca.fit_transform(X)\n",
    "y = data.loc[:, ['BinaryLabel']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "X_b = b_data.loc[:,cols_consider]\n",
    "y_b = b_data.loc[:, ['BinaryLabel']]\n",
    "Xb_train, Xb_test, yb_train, yb_test = train_test_split(X_b, y_b, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = ['Component/s', 'Environment','Project key', 'PrimaryCause', 'Cause1', 'Cause2','summary.1','summary.2','summary.3','summary.4','summary.5','summary.6','summary.7','summary.8','summary.9','summary.10','BinaryLabel']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.532697\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            BinaryLabel   No. Observations:                  401\n",
      "Model:                          Logit   Df Residuals:                      365\n",
      "Method:                           MLE   Df Model:                           35\n",
      "Date:                Fri, 22 Oct 2021   Pseudo R-squ.:                 0.08564\n",
      "Time:                        16:36:58   Log-Likelihood:                -213.61\n",
      "converged:                       True   LL-Null:                       -233.62\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.2573\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.3753     46.269      0.008      0.994     -90.311      91.061\n",
      "summary.1    -20.3114     21.498     -0.945      0.345     -62.446      21.824\n",
      "summary.2    -20.2006     23.930     -0.844      0.399     -67.103      26.702\n",
      "summary.3      9.3851     25.272      0.371      0.710     -40.147      58.917\n",
      "summary.4     -4.1888     21.650     -0.193      0.847     -46.622      38.245\n",
      "summary.5      4.5914     14.705      0.312      0.755     -24.230      33.413\n",
      "summary.6     12.9577     17.196      0.754      0.451     -20.745      46.661\n",
      "summary.7      3.2477     17.461      0.186      0.852     -30.976      37.472\n",
      "summary.8    -67.6627     24.025     -2.816      0.005    -114.750     -20.575\n",
      "summary.9    -15.5805     25.488     -0.611      0.541     -65.536      34.376\n",
      "summary.10    -4.3347     16.639     -0.261      0.794     -36.947      28.278\n",
      "primary.1     -4.8648     10.654     -0.457      0.648     -25.746      16.016\n",
      "primary.2      4.4841     12.748      0.352      0.725     -20.501      29.469\n",
      "primary.3     -8.2433     12.295     -0.670      0.503     -32.340      15.854\n",
      "primary.4     -8.2436     14.885     -0.554      0.580     -37.418      20.930\n",
      "primary.5      3.8915      9.758      0.399      0.690     -15.234      23.017\n",
      "cause1.1      -3.1312     10.069     -0.311      0.756     -22.867      16.604\n",
      "cause1.2      14.8356     11.899      1.247      0.212      -8.485      38.157\n",
      "cause1.3     -16.1102     11.182     -1.441      0.150     -38.026       5.806\n",
      "cause1.4       2.1914     12.139      0.181      0.857     -21.600      25.983\n",
      "cause1.5      -5.3942      6.918     -0.780      0.436     -18.954       8.166\n",
      "cause2.1       8.7239      7.203      1.211      0.226      -5.394      22.841\n",
      "cause2.2      18.6660     10.142      1.840      0.066      -1.212      38.544\n",
      "cause2.3      -5.4372      8.022     -0.678      0.498     -21.161      10.286\n",
      "cause2.4     -11.0881      8.250     -1.344      0.179     -27.258       5.082\n",
      "cause2.5      -7.5560      9.253     -0.817      0.414     -25.691      10.579\n",
      "cause3.1     -15.5374     37.183     -0.418      0.676     -88.415      57.340\n",
      "cause3.2     -28.2056     24.992     -1.129      0.259     -77.188      20.777\n",
      "cause3.3      21.0828     17.430      1.210      0.226     -13.079      55.245\n",
      "cause3.4      27.9703     18.718      1.494      0.135      -8.715      64.656\n",
      "cause3.5     -10.8987     10.378     -1.050      0.294     -31.239       9.442\n",
      "cause4.1       4.9392     12.405      0.398      0.691     -19.375      29.253\n",
      "cause4.2     -12.9340     33.274     -0.389      0.697     -78.149      52.281\n",
      "cause4.3      28.3642     40.927      0.693      0.488     -51.852     108.580\n",
      "cause4.4      19.7742     27.280      0.725      0.469     -33.693      73.241\n",
      "cause4.5       2.1977     16.139      0.136      0.892     -29.434      33.829\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "## Logisitc Regression\n",
    "#smote = SMOTE()\n",
    "X_train_constant = add_constant(X_train)\n",
    "model_logit = sm.Logit(y_train, X_train_constant)\n",
    "model_logit_result = model_logit.fit()\n",
    "print(model_logit_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_feature_elem (data_frame,dep_var,col_list):\n",
    "    removed_cols = []\n",
    "    while len(col_list)>0 :\n",
    "        model=sm.Logit(dep_var,data_frame[col_list])\n",
    "        result=model.fit(disp=0)\n",
    "        largest_pvalue=round(result.pvalues,3).nlargest(1)\n",
    "        if largest_pvalue[0]<(0.1):\n",
    "            return result, removed_cols\n",
    "            break\n",
    "        else:\n",
    "            removed_cols.append(largest_pvalue.index[0])\n",
    "            #print(\"removing :\",largest_pvalue.index)\n",
    "            col_list.remove(largest_pvalue.index)\n",
    "\n",
    "result, new_features = back_feature_elem(X_train_constant,y_train,cols_consider[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>BinaryLabel</td>   <th>  No. Observations:  </th>  <td>   401</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   394</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 22 Oct 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.04718</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>16:37:08</td>     <th>  Log-Likelihood:    </th> <td> -222.60</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -233.62</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>0.001190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>summary.6</th> <td>   17.2413</td> <td>    4.975</td> <td>    3.465</td> <td> 0.001</td> <td>    7.490</td> <td>   26.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>summary.8</th> <td>  -43.1855</td> <td>   13.772</td> <td>   -3.136</td> <td> 0.002</td> <td>  -70.178</td> <td>  -16.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cause1.2</th>  <td>   15.2999</td> <td>    7.368</td> <td>    2.076</td> <td> 0.038</td> <td>    0.858</td> <td>   29.742</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cause1.3</th>  <td>  -14.0253</td> <td>    7.324</td> <td>   -1.915</td> <td> 0.056</td> <td>  -28.381</td> <td>    0.330</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cause1.5</th>  <td>   -6.6689</td> <td>    3.677</td> <td>   -1.814</td> <td> 0.070</td> <td>  -13.875</td> <td>    0.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cause3.2</th>  <td>  -10.7927</td> <td>    4.207</td> <td>   -2.565</td> <td> 0.010</td> <td>  -19.039</td> <td>   -2.547</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cause3.5</th>  <td>  -10.0461</td> <td>    4.608</td> <td>   -2.180</td> <td> 0.029</td> <td>  -19.078</td> <td>   -1.014</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:            BinaryLabel   No. Observations:                  401\n",
       "Model:                          Logit   Df Residuals:                      394\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Fri, 22 Oct 2021   Pseudo R-squ.:                 0.04718\n",
       "Time:                        16:37:08   Log-Likelihood:                -222.60\n",
       "converged:                       True   LL-Null:                       -233.62\n",
       "Covariance Type:            nonrobust   LLR p-value:                  0.001190\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "summary.6     17.2413      4.975      3.465      0.001       7.490      26.993\n",
       "summary.8    -43.1855     13.772     -3.136      0.002     -70.178     -16.193\n",
       "cause1.2      15.2999      7.368      2.076      0.038       0.858      29.742\n",
       "cause1.3     -14.0253      7.324     -1.915      0.056     -28.381       0.330\n",
       "cause1.5      -6.6689      3.677     -1.814      0.070     -13.875       0.537\n",
       "cause3.2     -10.7927      4.207     -2.565      0.010     -19.039      -2.547\n",
       "cause3.5     -10.0461      4.608     -2.180      0.029     -19.078      -1.014\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_sk = LogisticRegression(penalty='l2',max_iter=100,random_state=SEED, class_weight='balanced').fit(X_train, y_train.to_numpy().ravel())\n",
    "logit_sk_b = LogisticRegression(penalty='l2',max_iter=100,random_state=SEED, class_weight='balanced').fit(X_train[new_features], y_train.to_numpy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = logit_sk.predict_proba(X_train)\n",
    "results_train_v2 = logit_sk.predict(X_train)\n",
    "results_test = logit_sk.predict_proba(X_test)\n",
    "results_test_v2 = logit_sk.predict(X_test)\n",
    "## New Feature set\n",
    "results_train_b = logit_sk_b.predict_proba(X_train[new_features])\n",
    "results_train_v2_b = logit_sk_b.predict(X_train[new_features])\n",
    "results_test_b = logit_sk_b.predict_proba(X_test[new_features])\n",
    "results_test_v2_b = logit_sk_b.predict(X_test[new_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Statistics for training data\n",
      "Predicted    0    1\n",
      "Actual             \n",
      "0           54   54\n",
      "1          104  189\n",
      "\n",
      "Precision is:  0.7777777777777778\n",
      "Recall is:  0.6450511945392492\n",
      "Overall_Accuracy is:  0.6059850374064838\n",
      "**************************************************\n",
      "Model Statistics for test data\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          11  12\n",
      "1          34  44\n",
      "\n",
      "Precision is:  0.7857142857142857\n",
      "Recall is:  0.5641025641025641\n",
      "Overall_Accuracy is:  0.5445544554455446\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Statistics for training data\")\n",
    "classification_stats(y_train.values.ravel(), results_train[:,1], results_train_v2)\n",
    "print(\"*****\"*10)\n",
    "print(\"Model Statistics for test data\")\n",
    "classification_stats(y_test.values.ravel(), results_test[:,1], results_test_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Statistics for training data\n",
      "Predicted    0    1\n",
      "Actual             \n",
      "0           53   55\n",
      "1          101  192\n",
      "\n",
      "Precision is:  0.7773279352226721\n",
      "Recall is:  0.6552901023890785\n",
      "Overall_Accuracy is:  0.6109725685785536\n",
      "**************************************************\n",
      "Model Statistics for test data\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          11  12\n",
      "1          31  47\n",
      "\n",
      "Precision is:  0.7966101694915254\n",
      "Recall is:  0.6025641025641025\n",
      "Overall_Accuracy is:  0.5742574257425742\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Statistics for training data\")\n",
    "classification_stats(y_train.values.ravel(), results_train_b[:,1], results_train_v2_b)\n",
    "print(\"*****\"*10)\n",
    "print(\"Model Statistics for test data\")\n",
    "classification_stats(y_test.values.ravel(), results_test_b[:,1], results_test_v2_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGBOOST\n",
    "hyper = OrderedDict({\n",
    "    'kfold':[5],\n",
    "    'n_estimators': [1,10,1],\n",
    "    'max_depth': range(1,10,1),\n",
    "    'learning_rate': [0.005,0.01,0.03,0.05,0.1],\n",
    "    'subsample': np.arange(0.10,1.0, 0.10),\n",
    "    'min_child_weight': range(1, 10,1)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:39:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:39:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suresh.nagulavancha\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\suresh.nagulavancha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.005, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=5, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=10, n_jobs=12, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Defining the model\n",
    "xgb = xgboost.sklearn.XGBClassifier(learning_rate =0.005,n_estimators=10,max_depth=4,min_child_weight=5,subsample=1,\\\n",
    "                         objective= 'binary:logistic',seed=SEED, scale_pos_weight=0.4)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_b = xgboost.sklearn.XGBClassifier(learning_rate =0.005,n_estimators=10,max_depth=4,min_child_weight=5,subsample=1,\\\n",
    "                         objective= 'binary:logistic',seed=SEED)\n",
    "xgb_b.fit(Xb_train, yb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = xgb.predict_proba(X_train)\n",
    "results_train_v2 = xgb.predict(X_train)\n",
    "results_test = xgb.predict_proba(X_test)\n",
    "results_test_v2 = xgb.predict(X_test)\n",
    "results_train_b = xgb_b.predict_proba(Xb_train)\n",
    "results_train_v2_b = xgb_b.predict(Xb_train)\n",
    "results_test_b = xgb_b.predict_proba(Xb_test)\n",
    "results_test_v2_b = xgb_b.predict(Xb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Model Statistics for training data\")\n",
    "#classification_stats(y_train.values.ravel(), results_train[:,1], results_train_v2)\n",
    "#print(\"*****\"*10)\n",
    "#print(\"Model Statistics for test data\")\n",
    "#classification_stats(y_test.values.ravel(), results_test[:,1], results_test_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Statistics for training data\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          85  20\n",
      "1          45  59\n",
      "\n",
      "Precision is:  0.7468354430379747\n",
      "Recall is:  0.5673076923076923\n",
      "Overall_Accuracy is:  0.6889952153110048\n",
      "**************************************************\n",
      "Model Statistics for test data\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          22   4\n",
      "1          12  15\n",
      "\n",
      "Precision is:  0.7894736842105263\n",
      "Recall is:  0.5555555555555556\n",
      "Overall_Accuracy is:  0.6981132075471698\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Statistics for training data\")\n",
    "classification_stats(yb_train.values.ravel(), results_train_b[:,1], results_train_v2_b)\n",
    "print(\"*****\"*10)\n",
    "print(\"Model Statistics for test data\")\n",
    "classification_stats(yb_test.values.ravel(), results_test_b[:,1], results_test_v2_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:  1.2min remaining:   21.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.2min finished\n",
      "C:\\Users\\suresh.nagulavancha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:765: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:    7.5s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    8.8s finished\n",
      "C:\\Users\\suresh.nagulavancha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:765: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "## Random Forest\n",
    "model_rf = RandomForestClassifier(n_estimators=10, class_weight='balanced')\n",
    "model_rf_b  = RandomForestClassifier(n_estimators=10)\n",
    "hyper_rf = OrderedDict({\n",
    "    'n_estimators': [10,1000,100],\n",
    "    'max_depth': range(1,10,1),\n",
    "    'min_samples_split':[10,100,10],\n",
    "    'min_samples_leaf':[1,10,1],\n",
    "    'max_features':['auto','sqrt'],\n",
    "    'bootstrap':[True,False]\n",
    "})\n",
    "model_rf_cv = RandomizedSearchCV(estimator=model_rf, param_distributions=hyper_rf, cv=3, verbose=2, n_jobs=-1)\n",
    "model_rf_cv_b = RandomizedSearchCV(estimator=model_rf_b, param_distributions=hyper_rf, cv=3, verbose=2, n_jobs=-1)\n",
    "\n",
    "model_rf_cv = model_rf_cv.fit(X_train, y_train)\n",
    "model_rf_cv_b = model_rf_cv_b.fit(Xb_train, yb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = model_rf_cv.predict_proba(X_train)\n",
    "results_train_v2 = model_rf_cv.predict(X_train)\n",
    "results_test = model_rf_cv.predict_proba(X_test)\n",
    "results_test_v2 = model_rf_cv.predict(X_test)\n",
    "results_train_b = model_rf_cv_b.predict_proba(Xb_train)\n",
    "results_train_v2_b = model_rf_cv_b.predict(Xb_train)\n",
    "results_test_b = model_rf_cv_b.predict_proba(Xb_test)\n",
    "results_test_v2_b = model_rf_cv_b.predict(Xb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Statistics for training data\n",
      "Predicted    0    1\n",
      "Actual             \n",
      "0          100    8\n",
      "1           13  280\n",
      "\n",
      "Precision is:  0.9722222222222222\n",
      "Recall is:  0.9556313993174061\n",
      "Overall_Accuracy is:  0.9476309226932669\n",
      "**************************************************\n",
      "Model Statistics for test data\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          12  11\n",
      "1          23  55\n",
      "\n",
      "Precision is:  0.8333333333333334\n",
      "Recall is:  0.7051282051282052\n",
      "Overall_Accuracy is:  0.6633663366336634\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Statistics for training data\")\n",
    "classification_stats(y_train.values.ravel(), results_train[:,1], results_train_v2)\n",
    "print(\"*****\"*10)\n",
    "print(\"Model Statistics for test data\")\n",
    "classification_stats(y_test.values.ravel(), results_test[:,1], results_test_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Statistics for training data\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          63  42\n",
      "1          21  83\n",
      "\n",
      "Precision is:  0.664\n",
      "Recall is:  0.7980769230769231\n",
      "Overall_Accuracy is:  0.6985645933014354\n",
      "**************************************************\n",
      "Model Statistics for test data\n",
      "Predicted  0   1\n",
      "Actual          \n",
      "0          8  18\n",
      "1          9  18\n",
      "\n",
      "Precision is:  0.5\n",
      "Recall is:  0.6666666666666666\n",
      "Overall_Accuracy is:  0.49056603773584906\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Statistics for training data\")\n",
    "classification_stats(yb_train.values.ravel(), results_train_b[:,1], results_train_v2_b)\n",
    "print(\"*****\"*10)\n",
    "print(\"Model Statistics for test data\")\n",
    "classification_stats(yb_test.values.ravel(), results_test_b[:,1], results_test_v2_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
